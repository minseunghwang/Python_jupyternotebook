{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 28, 28, 32)\n",
      "(?, 14, 14, 32)\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "INFO:tensorflow:Restoring parameters from ./model4\\cnn_model.ckpt-1000\n",
      "0.9991636\n",
      "정확도 : 0.9991636276245117\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "print(L1.shape)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "print(L1.shape)\n",
    "\n",
    "\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "print(L2.shape)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "print(L2.shape)\n",
    "\n",
    "## (?, 7, 7, 64)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# # 학습\n",
    "# training_echo = 30\n",
    "# batch_size = 100\n",
    "\n",
    "# for step in range(training_echo):\n",
    "#     num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "#     cost_val = 0\n",
    "#     for i in range(num_of_iter):\n",
    "#         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "#         _,cost_val = sess.run([train,cost], feed_dict = {X:batch_x,Y:batch_y, keep_prob:0.7})\n",
    "#     if step % 1 ==0:\n",
    "#         print(cost_val)\n",
    "# saver.save(sess, './model4/cnn_model.ckpt', global_step=1000)\n",
    "\n",
    "\n",
    "# Accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1)) # -> 두 개의 인자가 같아야 예측이 잘 수행된 것\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:0.7})\n",
    "print(result)\n",
    "print('정확도 : {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.07629    -0.         -0.         -0.         -0.         -0.\n",
      "   0.16560817 -0.          0.41850924 -0.        ]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('./data/number/0.png')\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "io.imshow(img_test)\n",
    "plt.show()\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img = Image.open('./data/number/0.png')\n",
    "#img = Image.open(sys.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result)\n",
    "#print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env3] *",
   "language": "python",
   "name": "conda-env-cpu_env3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
