{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-347e7ee0ce21>:73: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-347e7ee0ce21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saver' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# # placeholder \n",
    "# X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "# Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "# #rate=tf.placeholder(dtype=tf.float32)\n",
    "# keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "# ## 2.2.1 Convolution Layer1\n",
    "# # kernel_size 는 필터의 크기\n",
    "# L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "# print(L1.shape)\n",
    "# L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "# print(L1.shape)\n",
    "\n",
    "\n",
    "\n",
    "# ## 2.2.1 Convolution Layer2\n",
    "# L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "# print(L2.shape)\n",
    "# L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "# print(L2.shape)\n",
    "\n",
    "# ## (?, 7, 7, 64)\n",
    "\n",
    "# ## 2.3 Neural Network\n",
    "# L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# # shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "# W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "# _layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "# layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "# W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "# #Hypothesis\n",
    "# logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "# H = tf.nn.relu(logits)\n",
    "\n",
    "# # cost Function\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# # train\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "# train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# # Session & 초기화\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# # 학습\n",
    "# training_echo = 30\n",
    "# batch_size = 100\n",
    "\n",
    "# for step in range(training_echo):\n",
    "#     num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "#     cost_val = 0\n",
    "#     for i in range(num_of_iter):\n",
    "#         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "#         _,cost_val = sess.run([train,cost], feed_dict = {X:batch_x,Y:batch_y, keep_prob:0.7})\n",
    "#     if step % 1 ==0:\n",
    "#         print(cost_val)\n",
    "# saver.save(sess, './model4/cnn_model.ckpt', global_step=1000)\n",
    "\n",
    "\n",
    "# Accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1)) # -> 두 개의 인자가 같아야 예측이 잘 수행된 것\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:0.7})\n",
    "print(result)\n",
    "print('정확도 : {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.85882354, 0.63529414, 0.6392157 , 0.84705883,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.2627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14117648, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.1764706 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.9764706 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.5372549 , 0.        , 0.        ,\n",
       "        0.8039216 , 1.        , 1.        , 0.92156863, 0.01568628,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 0.8509804 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.04705882, 0.        ,\n",
       "        0.02352941, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.3764706 , 0.        , 0.32941177,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.24313726,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.8117647 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.7764706 , 0.        , 0.28627452,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.654902  ,\n",
       "        0.        , 0.11372549, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.40392157, 0.        , 0.6509804 , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.02352941, 0.        ,\n",
       "        0.8784314 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.16078432, 0.        ,\n",
       "        0.99607843, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.5921569 , 0.        , 0.4392157 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.08235294, 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.8901961 ,\n",
       "        0.        , 0.33333334, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.8745098 , 0.        , 0.34117648,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.07450981, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.87058824, 0.        , 0.34117648, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.07843138, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.75686276, 0.        ,\n",
       "        0.44705883, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.5137255 , 0.        , 0.6039216 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.21176471, 0.        , 0.8392157 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.09019608,\n",
       "        0.        , 0.92941177, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.5882353 ,\n",
       "        0.        , 0.3764706 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.9098039 , 0.        , 0.05490196, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.92941177, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.1764706 ,\n",
       "        0.        , 0.5254902 , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.40392157, 0.        , 0.        , 0.654902  ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.62352943, 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.1254902 , 0.        , 0.        , 0.        , 0.17254902,\n",
       "        0.40784314, 0.39215687, 0.4       , 0.32156864, 0.        ,\n",
       "        0.        , 0.76862746, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.4117647 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.42352942, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.7019608 ,\n",
       "        0.41568628, 0.24313726, 0.25490198, 0.25490198, 0.24313726,\n",
       "        0.70980394, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a2fa35c2bfa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.3\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mresult2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('./data/number/0.png')\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "io.imshow(img_test)\n",
    "plt.show()\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "display(test_img)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-3-71f653afb761>:27: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-71f653afb761>:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-71f653afb761>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Restoring parameters from ./model4\\cnn_model.ckpt-1000\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img = Image.open('./data/number/1.png')\n",
    "#img = Image.open(sys.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result)\n",
    "#print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from ./model4\\cnn_model.ckpt-1000\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "## 저장데이터 불러와보기\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# # placeholder \n",
    "# X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "# Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "# #rate=tf.placeholder(dtype=tf.float32)\n",
    "# keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "# ## 2.2.1 Convolution Layer1\n",
    "# # kernel_size 는 필터의 크기\n",
    "# L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "# print(L1.shape)\n",
    "# L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "# print(L1.shape)\n",
    "\n",
    "\n",
    "\n",
    "# ## 2.2.1 Convolution Layer2\n",
    "# L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "# print(L2.shape)\n",
    "# L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "# print(L2.shape)\n",
    "\n",
    "# ## (?, 7, 7, 64)\n",
    "\n",
    "# ## 2.3 Neural Network\n",
    "# L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# # shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "# W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "# _layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "# layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "# W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "# #Hypothesis\n",
    "# logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "# H = tf.nn.relu(logits)\n",
    "\n",
    "# # cost Function\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# # train\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "# train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# # Session & 초기화\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.import_meta_graph('./model4/cnn_model.ckpt-1000.meta')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./model4/cnn_model.ckpt-1000.meta')\n",
    "    new_saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "# global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "# ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "# if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "#     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "# else : \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Accuracy 측정\n",
    "# predict = tf.argmax(H,1)\n",
    "# correct = tf.equal(predict, tf.argmax(Y,1)) # -> 두 개의 인자가 같아야 예측이 잘 수행된 것\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# result = sess.run(accuracy, feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:0.7})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[1;32m-> 1092\u001b[1;33m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[0;32m   1093\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3477\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3478\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3556\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3557\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3558\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-9cf7ad81ec0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.3\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mresult2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1093\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m             raise TypeError(\n\u001b[1;32m-> 1095\u001b[1;33m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "img = Image.open('./data/number/2.png')\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "io.imshow(img_test)\n",
    "plt.show()\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from ./model4\\cnn_model.ckpt-1000\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img = Image.open('./data/number/5.png')\n",
    "# img = Image.open(sys.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result)\n",
    "#print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "0.09969091\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# Accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1)) # -> 두 개의 인자가 같아야 예측이 잘 수행된 것\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X:mnist.train.images, Y:mnist.train.labels, keep_prob:0.7})\n",
    "print(result)\n",
    "\n",
    "# saver = tf.train.import_meta_graph('./model4/cnn_model.ckpt-1000.meta')\n",
    "\n",
    "# ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "# # tf.reset_default_graph()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     new_saver = tf.train.import_meta_graph('./model4/cnn_model.ckpt-1000.meta')\n",
    "#     new_saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "# ckpt = tf.train.get_checkpoint_state('./model4')\n",
    "# if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "#     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "# else : \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# img = Image.open('./data/number/0.png')\n",
    "# # img = Image.open(sys.argv[1])\n",
    "\n",
    "# img_test =  img.resize((28,28))\n",
    "# img = np.array(img_test)\n",
    "# img_test = color.rgb2gray(img)\n",
    "\n",
    "# img_test = img_test.astype(np.float32)\n",
    "# test_img = img_test.reshape(-1, 784)\n",
    "# test_img = 1-test_img\n",
    "\n",
    "# predict = tf.argmax(H,1)\n",
    "# result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "# result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "# print(result)\n",
    "# #print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from C:\\python_ML\\model4\\cnn_model.ckpt-1000\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('C:\\python_ML\\model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img = Image.open('./data/number/1.png')\n",
    "# img = Image.open(sys.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result)\n",
    "#print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-3-a3660b943be3>:27: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-a3660b943be3>:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-a3660b943be3>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Restoring parameters from C:\\python_ML\\model4\\cnn_model.ckpt-1000\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "#rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "## 2.2.1 Convolution Layer1\n",
    "# kernel_size 는 필터의 크기\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=32, kernel_size=[3,3], padding='SAME', strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2], padding='SAME', strides=2)\n",
    "\n",
    "## 2.3 Neural Network\n",
    "L2 = tf.reshape(L2,[-1,7*7*32])\n",
    "\n",
    "# shape [, logist의 개수 (logist layer에 얼마나 많이 분포 하는지 )]\n",
    "W1 = tf.get_variable('weight1', shape=[7*7*32,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name='bias1')\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2, W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_prob) \n",
    "\n",
    "\n",
    "W2 = tf.get_variable('weight2', shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "\n",
    "#Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "# train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('C:\\python_ML\\model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img = Image.open('./data/number/2.png')\n",
    "# img = Image.open(sys.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result)\n",
    "#print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"ArgMax_14:0\", shape=(?,), dtype=int64)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Placeholder_2:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(predict)\n",
    "print(H)\n",
    "print(keep_prob)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from C:\\python_ML\\model4\\cnn_model.ckpt-1000\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('C:\\python_ML\\model4')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "img = Image.open('./data/number/99.png')\n",
    "# img = Image.open(sys.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(result)\n",
    "\n",
    "\n",
    "#print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env3] *",
   "language": "python",
   "name": "conda-env-cpu_env3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
