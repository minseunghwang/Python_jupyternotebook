{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a37edd82bcf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 필요한 module import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "# 필요한 module import\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) # 우리가 사용할 데이터파일의 압축파일이 쏙 들어가는 곳 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Model 정의(Tensorflow graph 생성)\n",
    "tf.reset_default_graph() # tensorflow graph 초기화\n",
    "## 2.1 placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "drop_rate = tf.placeholder(dtype=tf.float32)\n",
    "## 2.2 Convolution\n",
    "## CNN은 이미지 학습에 최적화된 depp learning 방법\n",
    "## 입력받은 이미지의 형태가 4차원 매트릭스\n",
    "## (이미지의 개수, 이미지의 width, 이미지 height, color수)\n",
    "X_img=tf.reshape(X, [-1,28,28,1])\n",
    "## 2.3 Convolution\n",
    "## filter 정의 => filter의 shape()\n",
    "# filter1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "# ## filter를 이용해서 Convolution image를 생성\n",
    "# # 원본이미지화 필터이미지를 행렬곱 연산을해서 컨벌루젼 이미지를 만든다(정확하게는 activation이미지 생성)\n",
    "# L1 = tf.nn.conv2d(X_img,filter1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "# ## 만들어진 Convolution에 Relu를 적용\n",
    "# L1 = tf.nn.relu(L1)\n",
    "# ## pooloing 작업(reesize, sampling 작업) => optional\n",
    "# L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") # kernel 사이즈 가로2 세로2 의미\n",
    "\n",
    "# 첫번째 컨벌루젼 레이어 ~하고, 렐루하고, 풀링하고 ?\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=3, kernel_size=[3,3], padding=\"SAME\",strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs = L1, pool_size=[2,2], padding=\"SAME\", strides=2) # ksize를 poo_size로 바꿔ㅜ줄거\n",
    "# 레이어가 많을수록 이미지의 갯수는 많아지지만 크기가 작아지므로 데이터 손실이 일어남 => 적정한 갯수 찾아야함\n",
    "\n",
    "## Convolution Layer2\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=6, kernel_size=[3,3], padding=\"SAME\", strides=1, activation=tf.nn.relu)\n",
    "\n",
    "L2 = tf.layers.max_pooling2d(inputs = L2, pool_size=[2,2], padding=\"SAME\", strides=2) # maxpooling\n",
    "\n",
    "print(L2.shape)\n",
    "# (?,7,7,64) # 7x7 짜리가 64개 존재해\n",
    "## 2.3 Nural Network\n",
    "## Convolution의 결과(4차원)를\n",
    "## Neural Network의 입력(2차원)으로 사용하기 위해 shape을 변경\n",
    "L2 = tf.reshape(L2,[-1,7*7*6])\n",
    "\n",
    "W1 = tf.get_variable(\"weight1\", shape=[7*7*6, 256], initializer=tf.contrib.layers.xavier_initializer()) # 컬럼의갯수, 아웃풋갯수(임의)\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W1) + b1)\n",
    "layer1 = tf.layers.dropout(_layer1, rate=drop_rate)\n",
    "\n",
    "# 2번째 레이어\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer()) # 컬럼의갯수, 아웃풋갯수(임의)\n",
    "b2 = tf.Variable(tf.random_normal([10]), name=\"bias2\")\n",
    "\n",
    "## Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "## cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "## train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 진행 (batch처리)\n",
    "\n",
    "# Accuracy 흑정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 결국 우리 MNIST예제는 입력한 이미지 1개에 대해 예측한 결과가 H의 값으로 도출\n",
    "#### [0.5, 0.8, 0.99, 0.12, 0.34, ...] 총 10개 # 가장큰 0.99가 몇번째에 있는지 찾자\n",
    "\n",
    "#### 앙상블은 이런 model이 여러개 있어요!\n",
    "#### H1 => [0.5, 0.8, 0.99, 0.12, 0.34 ...]\n",
    "#### H2 => [0.2, 0.3, 0.94, 0.5, 0.1 ...]\n",
    "#### H3 => [0.7, 0.1, 0.3, 0.2, 0.12 ...]\n",
    "#### H4 => [0.26, 0.23, 0.194, 0.56, 0.31 ...]\n",
    "\n",
    "#### SUM => [1.66, 1.43, 2.4, 1.3, 1.2 ...]\n",
    "#### 최종 prediction은 SUM한 결과값을 가지고 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5926214\n",
      "0.47709733\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-d33b7ece4fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 기본 MNIST(multinomial classification) \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Loading\n",
    "# mnist = input_data.read_data_sets(\"./data/mnist\",one_hot=True)\n",
    "\n",
    "train_data = pd.read_csv(\"./data/kaggle/train.csv\")\n",
    "train_x_data = train_data.drop('label', axis = 1)\n",
    "train_y_data = tf.one_hot(train_data[\"label\"], depth=10).eval(session = tf.Session())\n",
    "test_x_data = pd.read_csv(\"./data/kaggle/test.csv\")\n",
    "\n",
    "# Tensorflow Graph Initialization\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape = [None, 784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 10], dtype = tf.float32)\n",
    "drop_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Convolution\n",
    "x_img = tf.reshape(X, [-1,28,28,1])\n",
    "\n",
    "# W1 = tf.Variable(tf.random_normal(shape=[2,2,1,6]), name=\"filter1\")\n",
    "# L1 = tf.nn.conv2d(x_img, W1, strides=[1,2,2,1], padding=\"SAME\")\n",
    "# L1 = tf.nn.relu(L1)\n",
    "# L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "L1 = tf.layers.conv2d(inputs=x_img, filters=3, kernel_size=[2,2], padding=\"SAME\",strides=1, activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs = L1, pool_size=[2,2], padding=\"SAME\", strides=2) # ksize를 poo_size로 바꿔ㅜ줄거\n",
    "\n",
    "## 2.2.1 Convolution Layer2\n",
    "# W2 = tf.Variable(tf.random_normal(shape=[3,3,6,12]), name=\"filter2\")\n",
    "# L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "# L2 = tf.nn.relu(L2)\n",
    "\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=3, kernel_size=[2,2], padding=\"SAME\",strides=1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs = L2, pool_size=[2,2], padding=\"SAME\", strides=2)\n",
    "\n",
    "L2 = tf.reshape(L2, [-1,7*7*3])\n",
    "W3 = tf.get_variable(\"weight\", shape=[7*7*3,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal(shape=[10]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(L2,W3) + b\n",
    "H = tf.nn.relu(logits)\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\n",
    "\n",
    "# train node\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# session object & initialization\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# epoch & batch size\n",
    "training_epoch = 5 # 니가학습 몇번시킬래\n",
    "batch_size = 100 # 데이터를 몇등분해서 학습시킬래 # 환경이좋으면 작게 넣어서 한번에 여러번 학습\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# training\n",
    "for step in range(training_epoch):\n",
    "    num_of_iteration = int(train_data.shape[0] / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iteration):\n",
    "        batch_x, batch_y = train_x_data[i*batch_size:(i+1)*batch_size],train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_x, Y: batch_y, drop_rate: 0.3})\n",
    "\n",
    "    if step %2 == 0:\n",
    "        print(cost_val)\n",
    "        \n",
    "\n",
    "saver.save(sess, './model/practice_model.ckpt', global_step=1000)\n",
    "\n",
    "# #predict check\n",
    "predict = tf.argmax(H,1)\n",
    "# result = sess.run(predict, feed_dict={X:test_x_data, drop_rate: 0.3})\n",
    "# df = pd.DataFrame({\n",
    "#     'ImageId': [i for i in range(1,28001)],\n",
    "#     'Label': result\n",
    "# })\n",
    "# df.to_csv('./data/kaggle/submission2.csv', index=False)\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'ImageId': [i for i in range(1,28001)],\n",
    "#     'Label': sess.run(H,feed_dict={X:test_x_data, drop_rate: 0.3})\n",
    "# })\n",
    "# df.to_csv('./data/kaggle/ms.csv', index=False)\n",
    "\n",
    "\n",
    "# accuracy check\n",
    "correct = tf.equal(predict, tf.math.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"Accuracy: {}\".format(sess.run(accuracy, feed_dict = {X: train_x_data, Y: train_y_data, drop_rate:0.3})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import data, io, filters, color\n",
    "\n",
    "# img2 = io.imread(\"./data/number2/0.png\", as_gray=True) # bmp 넘파이로 드러와서 리싸이즈가 안대유\n",
    "img = Image.open('./data/number/6.png')\n",
    "img_test =  img.resize((28,28))\n",
    "img2 = np.array(img_test)\n",
    "img3 = color.rgb2gray(img2)\n",
    "\n",
    "print(img2.shape)\n",
    "print(img3.shape)\n",
    "\n",
    "io.imshow(img3)\n",
    "plt.show()\n",
    "img3= 1-img3\n",
    "x_data = img3.reshape(-1,784)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[[ 0.08068627 -0.         -0.          1.277905   -0.          0.69681656\n",
      "  -0.          0.4087038  -0.         -0.        ]]\n"
     ]
    }
   ],
   "source": [
    "predict = tf.argmax(H,1)\n",
    "result=sess.run(predict, feed_dict = {X:x_data, drop_rate:0.3})\n",
    "result2=sess.run(H, feed_dict = {X:x_data, drop_rate:0.3})\n",
    "\n",
    "print(result)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch & batch size\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3 })\n",
    "print(result2)\n",
    "print(result)\n",
    "training_epoch = 5 # 니가학습 몇번시킬래\n",
    "batch_size = 100 # 데이터를 몇등분해서 학습시킬래 # 환경이좋으면 작게 넣어서 한번에 여러번 학습\n",
    "\n",
    "# training\n",
    "for step in range(training_epoch):\n",
    "    num_of_iteration = int(train_data.shape[0] / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iteration):\n",
    "        batch_x, batch_y = train_x_data[i*batch_size:(i+1)*batch_size],train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_x, Y: batch_y, drop_rate: 0.3})\n",
    "\n",
    "    if step %2 == 0:\n",
    "        print(cost_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-1f020e9ec695>:90: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-1f020e9ec695>:34: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-1f020e9ec695>:39: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-1f020e9ec695>:58: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "## Ensemble MNIST ooo\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "## Graph init\n",
    "tf.reset_default_graph()\n",
    "## Class Define\n",
    "## cnn model \n",
    "class CnnModel:\n",
    "        # constructor\n",
    "        def __init__(self,sess,name,m,test):\n",
    "            self.sess = sess\n",
    "            self.name = name\n",
    "            self.mnist = m\n",
    "            self.test_x_data = test\n",
    "            self.build_net()\n",
    "         \n",
    "        # tensorflow model graph(node) method    \n",
    "        def build_net(self):    \n",
    "            with tf.variable_scope(self.name):\n",
    "\n",
    "                # tensorflow graph init\n",
    "                self.X = tf.placeholder(shape = [None,784], dtype = tf.float32)\n",
    "                self.Y = tf.placeholder(shape = [None,10], dtype = tf.float32)\n",
    "                self.drop_rate = tf.placeholder(dtype = tf.float32)\n",
    "                X_img = tf.reshape(self.X,[-1,28,28,1])\n",
    "\n",
    "                L1 = tf.layers.conv2d(inputs=X_img,\n",
    "                                      filters = 1,\n",
    "                                      kernel_size=[3,3],\n",
    "                                      padding= \"SAME\",\n",
    "                                      strides=1,\n",
    "                                      activation=tf.nn.relu)\n",
    "\n",
    "                L1 = tf.layers.max_pooling2d(inputs= L1,\n",
    "                                             pool_size=[2,2],\n",
    "                                             strides = 2,\n",
    "                                             padding = \"SAME\")\n",
    "\n",
    "                L2 = tf.layers.conv2d(inputs=L1,\n",
    "                                      filters = 1,\n",
    "                                      kernel_size=[3,3],\n",
    "                                      padding= \"SAME\",\n",
    "                                      strides=1,\n",
    "                                      activation=tf.nn.relu)\n",
    "\n",
    "                L2 = tf.layers.max_pooling2d(inputs= L2,\n",
    "                                             pool_size=[2,2],\n",
    "                                             strides = 2,\n",
    "                                             padding = \"SAME\")\n",
    "\n",
    "                L2 = tf.reshape(L2, [-1,7*7*1])\n",
    "\n",
    "                W1 = tf.get_variable(\"weight1\",shape = [7*7*1,32],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b1 = tf.Variable(tf.random_normal([32]),name = \"bias1\")\n",
    "                _layer1 = tf.nn.relu(tf.matmul(L2,W1)+ b1)\n",
    "                layer1 = tf.layers.dropout (_layer1, rate = self.drop_rate)\n",
    "\n",
    "                W2 = tf.get_variable(\"weight2\",shape = [32,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b2 = tf.Variable(tf.random_normal([10]),name = \"bias2\")\n",
    "\n",
    "                self.logits = tf.matmul(layer1,W2)+ b2\n",
    "                self.H = tf.nn.relu(self.logits)\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.Y))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "            self.train = self.optimizer.minimize(self.cost)\n",
    "            predict = tf.argmax(self.H,1)\n",
    "            correct = tf.equal(predict,tf.argmax(self.Y,1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "            \n",
    "        # model train\n",
    "        def train_net(self, train_x_data, train_y_data):\n",
    "            return sess.run([self.train, self.cost],feed_dict = {self.X : batch_x, self.Y: batch_y, self.drop_rate:0.7})\n",
    "           \n",
    "        \n",
    "        # model Accuracy\n",
    "        def get_accuracy(self,train_x_data, train_y_data):\n",
    "            self.result = self.sess.run(self.accuracy , feed_dict = {self.X:train_x_data,\n",
    "                                                       self.Y: train_y_data,\n",
    "                                                       self.drop_rate:0.7})\n",
    "            return self.result \n",
    "    \n",
    "        # model의 prediction\n",
    "        def get_prediction(self,x_data):\n",
    "            return self.sess.run(self.H,feed_dict={self.X:x_data,self.drop_rate:1.0})\n",
    "            \n",
    "## 1.Data loading\n",
    "mnist= input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "train= mnist.train\n",
    "test_x_data = pd.read_csv(\"./data/kaggle/test.csv\")\n",
    "# test_x_data = pd.read_csv(\"./data/digitrecognizer/test.csv\")\n",
    "\n",
    "## 2. Model number\n",
    "sess = tf.Session()\n",
    "\n",
    "training_epochs = 1\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_of_model = 2\n",
    "cnn_models = [CnnModel(sess,\"Model\" + str(x),train,test_x_data) for x in range(num_of_model)]\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for m in cnn_models:\n",
    "#     print(m.name)\n",
    "#     for step in range(training_epochs):\n",
    "#         num_of_iter = int(train.num_examples / batch_size)\n",
    "#         cost_val = 0\n",
    "#         for i in range(num_of_iter):\n",
    "#             batch_x, batch_y = train.next_batch(batch_size)\n",
    "#             _,cost_val = m.train_net(train.images,train.labels)\n",
    "#     print('Epoch: ', '%04d' %(step + 1), 'Cost = ', cost_val)\n",
    "#     print(m.get_accuracy(mnist.test.images,mnist.test.labels))\n",
    "# print('Training Finished')\n",
    "\n",
    "# saver.save(sess, './model/practice_model.ckpt', global_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "new_saver = tf.train.import_meta_graph('./check/practice_model.meta')\n",
    "new_saver.restore(sess, './check/practice_model')\n",
    "# tf.all_variables()\n",
    "X = sess.graph.get_tensor_by_name(\"Model0/Placeholder:0\")\n",
    "logits = sess.graph.get_tensor_by_name(\"Model0/add_1:0\")\n",
    "train = sess.graph.get_tensor_by_name(\"Model0/Placeholder_2:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.85882353 0.63529412 0.63921569 0.84705882 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.2627451\n",
      "  0.         0.         0.         0.         0.14117647 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.17647059 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.97647059 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.5372549  0.         0.\n",
      "  0.80392157 1.         1.         0.92156863 0.01568627 0.\n",
      "  0.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.         0.         0.85098039\n",
      "  1.         1.         1.         1.         1.         0.04705882\n",
      "  0.         0.02352941 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.37647059 0.         0.32941176 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.         0.         0.24313725 1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.         0.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         0.         0.         0.81176471 1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.77647059 0.         0.28627451 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         0.65490196 0.         0.11372549 1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.40392157 0.         0.65098039 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.02352941 0.         0.87843137 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.16078431 0.         0.99607843 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.59215686 0.         0.43921569 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.08235294 0.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.89019608 0.         0.33333333 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.         0.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.8745098  0.         0.34117647 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.         0.0745098  1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.87058824 0.         0.34117647 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.         0.07843137 1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.75686275 0.         0.44705882 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.         0.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.51372549 0.         0.60392157 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.21176471 0.         0.83921569 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.09019608 0.         0.92941176 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.58823529 0.         0.37647059 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         0.90980392 0.         0.05490196 1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.         0.         0.92941176 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         0.17647059 0.         0.5254902  1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.40392157 0.         0.         0.65490196\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.62352941 0.         0.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.1254902  0.         0.\n",
      "  0.         0.17254902 0.40784314 0.39215686 0.4        0.32156863\n",
      "  0.         0.         0.76862745 1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.41176471 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.42352941 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.70196078 0.41568627 0.24313725 0.25490196 0.25490196 0.24313725\n",
      "  0.70980392 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 6]\n",
      "[4 3 4]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from skimage import data, io, filters, color\n",
    "\n",
    "\n",
    "# img = Image.open('./data/number/8.png')\n",
    "# display(img)\n",
    "\n",
    "# img_test =  img.resize((28,28))\n",
    "# img = np.array(img_test)\n",
    "# img_test = color.rgb2gray(img)\n",
    "\n",
    "# io.imshow(img_test)\n",
    "# plt.show()\n",
    "\n",
    "# img_test = img_test.astype(np.float32)\n",
    "# test_img = img_test.reshape(-1, 784)\n",
    "# test_img = 1-test_img\n",
    "# print(test_img.shape)\n",
    "# display(test_img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(cnn_models.size)\n",
    "\n",
    "# mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) # 우리가 사용할 데이터파일의 압축파일이 쏙 들어가는 곳 ?\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "# new_saver = tf.train.import_meta_graph('./practice_model.meta')\n",
    "# new_saver.restore(sess, './practice_model')\n",
    "\n",
    "# X = sess.graph.get_tensor_by_name(\"Model0/Placeholder:0\")\n",
    "# logits = sess.graph.get_tensor_by_name(\"Model0/add_1:0\")\n",
    "# train = sess.graph.get_tensor_by_name(\"Model0/Placeholder_2:0\")\n",
    "# accuracy = sess.graph.get_tensor_by_name(\"Mean_1:0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def get_prediction(self,x_data):\n",
    "#     return self.sess.run(self.H,feed_dict={self.X:x_data,self.drop_rate:0.7})\n",
    "\n",
    "\n",
    "# img2 = io.imread(\"./data/number2/0.png\", as_gray=True) # bmp 넘파이로 드러와서 리싸이즈가 안대유\n",
    "img2 = Image.open('./data/number/0.png')\n",
    "img_test =  img2.resize((28,28))\n",
    "img2 = np.array(img_test)\n",
    "img3 = color.rgb2gray(img2)\n",
    "\n",
    "print(img3)\n",
    "\n",
    "io.imshow(img2)\n",
    "plt.show()\n",
    "# print(img2)\n",
    "img2= 1-img2\n",
    "# print(img2)\n",
    "x_data = img2.reshape(-1,784)\n",
    "\n",
    "for i in cnn_models:\n",
    "    result=i.get_prediction(x_data)\n",
    "    print(sess.run(tf.argmax(result,1)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABpUlEQVR4nN2VIasCQRSFzz4XFJsIotiMwloEUZlisxiMNn+A+BdswhZhrSaxGKwGo8FoE9wNWhQMgorB4MCuYWCRdWZW91neO2m4e+7H3LtzZxTHcfBt/Xyd+M+g0+m0Xq/ncrlarfYu1RFrOBx6zJqmSfyuhNBCoeCyCCGdToetd7tdQGg0GmWIdrvtBg3DAGAYhi9UfW1It9u93W4ANptNJpNx48ViEYBpmr4t5UBHoxGAw+GQTCaf4/v9HkA4HPaFcsrv9/vZbNYTnEwmzL9cLgP21KNqtcqIlUrlHb8PVNf157Ly+bxt27+Fcju2Wq3kWYook2k8Hpum2Wg0IpEIpbRcLh+PRwCn0ykWi33wo+QqlUoAEolE8PK5CoVCkI5WkFuq1+sBGAwGIgMHul6vFUW5XC6iHHbCLMv6ADqbzQB4DtOz2KRRSkUGTk/P57PoExMhBECz2RQZ+JmapgEghLiR+/0+n89brZa7G0rpZ1DH74m1LEuUKIMuFotXViqV0nVdgmOSTdT1et1ut6qq2rYdj8fT6bR8+658xjSY/s67/wBiNbdDoBVoWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x145062E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.70588235\n",
      "  0.31372549 0.17647059 0.29803922 1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.63137255 0.         0.\n",
      "  0.         0.         0.         0.17647059 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.21176471 0.         0.         0.\n",
      "  0.23529412 0.49803922 0.         0.         0.89019608 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.03921569 0.         0.         0.43137255 1.\n",
      "  1.         1.         0.56862745 0.         0.56862745 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.52156863 0.         0.         0.86666667 1.         1.\n",
      "  1.         1.         0.78823529 0.         0.41176471 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.15686275 0.         0.90588235 1.         1.         1.\n",
      "  1.         1.         0.67843137 0.         0.43921569 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.57254902 0.16470588 1.         1.         1.         1.\n",
      "  1.         0.6745098  0.         0.         0.80392157 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.28235294 0.         0.         0.25490196 1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.5372549  0.\n",
      "  0.         0.         0.         0.2        0.99607843 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.83137255\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.65490196 0.49803922\n",
      "  0.84705882 0.87843137 0.85882353 0.08235294 0.         0.\n",
      "  0.93333333 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.22352941 0.\n",
      "  0.08627451 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.01176471\n",
      "  0.         0.89019608 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.56862745\n",
      "  0.         0.49411765 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.83921569 0.         0.9372549  1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.85098039\n",
      "  0.         0.34117647 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.56078431 0.         0.47058824 1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.94509804\n",
      "  0.         0.32156863 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  0.9372549  0.         0.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.23529412\n",
      "  0.         0.37647059 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         0.17647059 0.         0.23529412 1.         1.\n",
      "  1.         0.98039216 0.75686275 0.42352941 0.         0.\n",
      "  0.         0.98431373 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.85098039 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         0.77254902 0.         0.         0.\n",
      "  0.         0.         0.         0.09803922 0.5372549  1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.94509804 0.81176471 0.82745098\n",
      "  0.81960784 0.89411765 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29411763, 0.6862745 ,\n",
       "        0.8235294 , 0.7019608 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.36862743,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.8235294 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7882353 , 1.        , 1.        , 1.        ,\n",
       "        0.7647059 , 0.50196075, 1.        , 1.        , 0.10980392,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.9607843 , 1.        ,\n",
       "        1.        , 0.5686275 , 0.        , 0.        , 0.        ,\n",
       "        0.43137252, 1.        , 0.43137252, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.47843134, 1.        , 1.        , 0.13333333, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2117647 , 1.        ,\n",
       "        0.58823526, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.84313726, 1.        ,\n",
       "        0.09411764, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3215686 , 1.        , 0.56078434, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.42745095, 0.8352941 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32549018, 1.        ,\n",
       "        1.        , 0.19607842, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.7176471 , 1.        , 1.        , 0.745098  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.46274507, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.8       , 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.16862744, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34509802, 0.50196075, 0.15294117,\n",
       "        0.12156862, 0.14117646, 0.91764706, 1.        , 1.        ,\n",
       "        0.06666666, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7764706 , 1.        , 0.9137255 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.9882353 , 1.        , 0.10980392, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43137252, 1.        ,\n",
       "        0.5058824 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1607843 , 1.        , 0.06274509, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1490196 , 1.        , 0.6588235 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43921566, 1.        ,\n",
       "        0.5294118 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        1.        , 0.6784314 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06274509, 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.7647059 , 1.        , 0.62352943,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.8235294 , 1.        , 0.7647059 , 0.        , 0.        ,\n",
       "        0.        , 0.01960784, 0.24313724, 0.5764706 , 1.        ,\n",
       "        1.        , 1.        , 0.01568627, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.1490196 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.22745097, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9019608 ,\n",
       "        0.46274507, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05490196, 0.18823528, 0.17254901, 0.18039215,\n",
       "        0.10588235, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('./data/number/3.png')\n",
    "display(img)\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "print(img_test)\n",
    "io.imshow(img_test)\n",
    "plt.show()\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "print(test_img.shape)\n",
    "display(test_img)\n",
    "\n",
    "\n",
    "\n",
    "for i in cnn_models:\n",
    "    result=i.get_prediction(test_img)\n",
    "    print(sess.run(tf.argmax(result,1)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  ...\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]]\n",
      "\n",
      " [[5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  ...\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]]\n",
      "\n",
      " [[5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  ...\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  ...\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]]\n",
      "\n",
      " [[5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  ...\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]]\n",
      "\n",
      " [[5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  ...\n",
      "  [5 5 5]\n",
      "  [5 5 5]\n",
      "  [5 5 5]]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# import sys\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "from skimage import data, io, filters, color\n",
    "\n",
    "\n",
    "im = Image.open('./data/number/0.png')\n",
    "\n",
    "pix = np.array(im)\n",
    "\n",
    "print(pix-250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env3] *",
   "language": "python",
   "name": "conda-env-cpu_env3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
