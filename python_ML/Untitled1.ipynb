{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Introduction ####\n",
    "\n",
    "# python에서 1줄 주석은 => # 입니다\n",
    "# python에서 여러줄 주석은 => \"\"\" \"\"\"\n",
    "\"\"\"\n",
    "1. DATA : 측정이나 관찰을 통해서 모아놓은 값의 집합\n",
    "         사실을 표현하는 하나의 단면일 뿐 그 자체가\n",
    "         의미를 가지지는 않아요!\n",
    "2. 이런 데이터를 기반으로 의미있는 내용(사실)을\n",
    "    끌어내는 작업 => Data Analysis(데이터 분석)\n",
    "    \n",
    "3. Big Data의 일반적인 의미\n",
    "    => 기존의 관리체계, 분석체계로 감당할 수 없는 많은\n",
    "    양의 데이터를 의미\n",
    "    \n",
    "4. Big Data의 3가지 특징(3V)\n",
    "    => 1. 데이터의 규모(Volumn)\n",
    "        GB -> TV -> PB -> EB -> ZB -> YB\n",
    "       2. 데이터의 다양성(Variety)\n",
    "        비 정형화된 형태의 데이터로 구성\n",
    "       3. 데이터의 발생속도(Velocity)\n",
    "        데이터가 실시간적으로 발생된다는 특징\n",
    "\n",
    "5. Big Data의 분석방법\n",
    "    => 1. EDA(Explore Data Analysis) : 탐색적 데이터 분석\n",
    "       2. 통계적 가설 검정\n",
    "       3. 머신러닝 - 많은양의 데이터를 기반으로 프로그램을 학습시켜서 분석\n",
    "\n",
    "6. 왜 Python인가요?\n",
    "    => Data분석에 최적화 되어있어요.\n",
    "    상대적으로 배우기가 쉬워요!\n",
    "    인터렉티브한 개발이 용이\n",
    "    아주아주 강려한 무료의 라이브러리(Numpy, Pandas)\n",
    "    단점) 2.x 버젼과 3.x 버젼의 호환성이 없어요!\n",
    "    \n",
    "7. 가장 많이 사용되는 프로그래밍 언어\n",
    "    주력으로 사용되는 언어 하나는 반드시 있어야 해요!\n",
    "    1. Java\n",
    "    2. C\n",
    "    3. python\n",
    "    4. C++\n",
    "    5. JavaScript\n",
    "    6. .Net\n",
    "\n",
    "\"\"\"\n",
    "'\\n이 부분은 다 주석처리되요 \\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name pywrap_tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e9b78403e187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name pywrap_tensorflow"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import warnings\n",
    "# 싸이키런\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Data Loading\n",
    "mnist= input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "sess = tf.Session()\n",
    "#ckpt = tf.train.get_checkpoint_state('C:\\python_ML\\model4')\n",
    "#if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "#    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "#else : \n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "new_saver = tf.train.import_meta_graph('C:\\python_ML\\model4\\cnn_model.ckpt-1000.meta')\n",
    "new_saver.restore(sess, 'C:\\python_ML\\model4\\cnn_model.ckpt-1000')\n",
    "\n",
    "#img = Image.open('./data/number/1.png')\n",
    "img = Image.open(says.argv[1])\n",
    "\n",
    "img_test =  img.resize((28,28))\n",
    "img = np.array(img_test)\n",
    "img_test = color.rgb2gray(img)\n",
    "\n",
    "img_test = img_test.astype(np.float32)\n",
    "test_img = img_test.reshape(-1, 784)\n",
    "test_img = 1-test_img\n",
    "\n",
    "\n",
    "\n",
    "X = sess.graph.get_tensor_by_name(\"Placeholder:0\")\n",
    "H = sess.graph.get_tensor_by_name(\"Relu_1:0\")\n",
    "keep_prob = sess.graph.get_tensor_by_name(\"Placeholder_2:0\")\n",
    "\n",
    "result2 = sess.run(H, feed_dict={X:test_img,keep_prob:0.3})\n",
    "print(sess.run(tf.argmax(result2,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env]",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
